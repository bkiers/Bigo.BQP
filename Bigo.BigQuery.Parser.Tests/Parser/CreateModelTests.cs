using Xunit;

namespace Bigo.BigQuery.Parser.Tests.Parser;

public class CreateModelTests : BaseParserTest
{
    [Theory]
    [InlineData("create model mu")]
    [InlineData("create model if not exists mu")]
    [InlineData("create or replace model mu")]
    [InlineData("CREATE OR REPLACE MODEL `myproject.mydataset.mymodel` TRANSFORM(ML.FEATURE_CROSS(STRUCT(f1, f2)))")]
    [InlineData("CREATE OR REPLACE MODEL `myproject.mydataset.mymodel` TRANSFORM(ML.FEATURE_CROSS(STRUCT(f1, f2)) as Foo)")]
    [InlineData("CREATE OR REPLACE MODEL `myproject.mydataset.mymodel`\n  TRANSFORM(ML.FEATURE_CROSS(STRUCT(f1, f2)) as cross_f,\n            ML.QUANTILE_BUCKETIZE(f3) OVER() as buckets,\n            label_col)\n  OPTIONS(model_type='linear_reg', input_label_cols=['label_col'])\nAS SELECT * FROM t")]
    [InlineData("CREATE MODEL\n  `mydataset.mymodel`\nOPTIONS\n  ( MODEL_TYPE='LINEAR_REG',\n    LS_INIT_LEARN_RATE=0.15,\n    L1_REG=1,\n    MAX_ITERATIONS=5 ) AS\nSELECT\n  column1,\n  column2,\n  column3,\n  label\nFROM\n  `mydataset.mytable`\nWHERE\n  column4 < 10")]
    [InlineData("CREATE MODEL\n  `mydataset.mymodel`\nOPTIONS\n  ( MODEL_TYPE='LINEAR_REG',\n    LS_INIT_LEARN_RATE=0.15,\n    L1_REG=1,\n    MAX_ITERATIONS=5,\n    DATA_SPLIT_METHOD='SEQ',\n    DATA_SPLIT_EVAL_FRACTION=0.3,\n    DATA_SPLIT_COL='timestamp' ) AS\nSELECT\n  column1,\n  column2,\n  column3,\n  timestamp,\n  label\nFROM\n  `mydataset.mytable`\nWHERE\n  column4 < 10")]
    [InlineData("CREATE MODEL\n  `mydataset.mymodel`\nOPTIONS\n  ( MODEL_TYPE='LINEAR_REG',\n    DATA_SPLIT_METHOD='CUSTOM',\n    DATA_SPLIT_COL='SPLIT_COL' ) AS\nSELECT\n  *,\n  false AS split_col\nFROM\n  `mydataset.training_table`\nUNION ALL\nSELECT\n  *,\n  true AS split_col\nFROM\n  `mydataset.evaluation_table`")]
    [InlineData("CREATE MODEL\n  `mydataset.mymodel`\nOPTIONS\n  ( MODEL_TYPE='LOGISTIC_REG',\n    AUTO_CLASS_WEIGHTS=TRUE ) AS\nSELECT\n  *\nFROM\n  `mydataset.mytable`")]
    [InlineData("CREATE MODEL\n  `mydataset.mymodel`\nOPTIONS\n  ( MODEL_TYPE='LOGISTIC_REG',\n    CLASS_WEIGHTS=[('label1', 0.5), ('label2', 0.3), ('label3', 0.2)]) AS\nSELECT\n  *\nFROM\n  `mydataset.mytable`")]
    [InlineData("CREATE MODEL\n  `mydataset.mymodel`\nOPTIONS\n  ( MODEL_TYPE='LOGISTIC_REG',\n    CLASS_WEIGHTS=[('0', 0.9), ('1', 0.1)]) AS\nSELECT\n  *\nFROM\n  `mydataset.mytable`")]
    [InlineData("CREATE MODEL `mydataset.mymodel`\n  TRANSFORM(f1 + f2 as c, * EXCEPT(f1, f2))\n  OPTIONS(model_type='linear_reg', input_label_cols=['label_col'])\nAS SELECT f1, f2, f3, label_col FROM t")]
    [InlineData("CREATE MODEL `project_id.mydataset.mymodel`\nOPTIONS(MODEL_TYPE='BOOSTED_TREE_CLASSIFIER',\n        BOOSTER_TYPE = 'GBTREE',\n        NUM_PARALLEL_TREE = 1,\n        MAX_ITERATIONS = 50,\n        TREE_METHOD = 'HIST',\n        EARLY_STOP = FALSE,\n        SUBSAMPLE = 0.85,\n        INPUT_LABEL_COLS = ['mylabel'])\nAS SELECT * FROM `project_id.mydataset.mytable`")]
    [InlineData("CREATE MODEL `project_id.mydataset.mymodel`\nOPTIONS(MODEL_TYPE='RANDOM_FOREST_CLASSIFIER',\n        NUM_PARALLEL_TREE = 50,\n        TREE_METHOD = 'HIST',\n        EARLY_STOP = FALSE,\n        SUBSAMPLE = 0.85,\n        INPUT_LABEL_COLS = ['mylabel'])\nAS SELECT * FROM `project_id.mydataset.mytable`")]
    [InlineData("CREATE MODEL `project_id.mydataset.mymodel`\nOPTIONS(MODEL_TYPE='DNN_CLASSIFIER',\n        ACTIVATION_FN = 'RELU',\n        BATCH_SIZE = 16,\n        DROPOUT = 0.1,\n        EARLY_STOP = FALSE,\n        HIDDEN_UNITS = [128, 128, 128],\n        INPUT_LABEL_COLS = ['mylabel'],\n        LEARN_RATE=0.001,\n        MAX_ITERATIONS = 50,\n        OPTIMIZER = 'ADAGRAD')\nAS SELECT * FROM `project_id.mydataset.mytable`")]
    [InlineData("CREATE MODEL `project_id.mydataset.mymodel`\nOPTIONS(MODEL_TYPE='DNN_LINEAR_COMBINED_CLASSIFIER',\n        ACTIVATION_FN = 'RELU',\n        BATCH_SIZE = 16,\n        DROPOUT = 0.1,\n        EARLY_STOP = FALSE,\n        HIDDEN_UNITS = [128, 128, 128],\n        INPUT_LABEL_COLS = ['mylabel'],\n        LEARN_RATE=0.001,\n        MAX_ITERATIONS = 50,\n        OPTIMIZER = 'ADAGRAD')\nAS SELECT * FROM `project_id.mydataset.mytable`")]
    [InlineData("CREATE OR REPLACE MODEL `project_id.mydataset.mymodel`\n       OPTIONS(model_type='AUTOML_REGRESSOR',\n               input_label_cols=['fare_amount'],\n               budget_hours=1.0)\nAS SELECT\n  (tolls_amount + fare_amount) AS fare_amount,\n  pickup_longitude,\n  pickup_latitude,\n  dropoff_longitude,\n  dropoff_latitude,\n  passenger_count\nFROM `nyc-tlc.yellow.trips`\nWHERE ABS(MOD(FARM_FINGERPRINT(CAST(pickup_datetime AS STRING)), 100000)) = 1\nAND\n  trip_distance > 0\n  AND fare_amount >= 2.5 AND fare_amount <= 100.0\n  AND pickup_longitude > -78\n  AND pickup_longitude < -70\n  AND dropoff_longitude > -78\n  AND dropoff_longitude < -70\n  AND pickup_latitude > 37\n  AND pickup_latitude < 45\n  AND dropoff_latitude > 37\n  AND dropoff_latitude < 45\n  AND passenger_count > 0")]
    [InlineData("CREATE MODEL\n  `mydataset.mymodel`\nOPTIONS\n  ( MODEL_TYPE='KMEANS',\n    NUM_CLUSTERS=4 ) AS\nSELECT\n  *\nFROM\n  `mydataset.mytable`")]
    [InlineData("CREATE MODEL\n  `mydataset.mymodel`\nOPTIONS\n  ( MODEL_TYPE='KMEANS',\n    NUM_CLUSTERS=3,\n    KMEANS_INIT_METHOD='RANDOM') AS\nSELECT\n  *\nFROM\n  `mydataset.mytable`")]
    [InlineData("CREATE MODEL\n  `mydataset.mymodel`\nOPTIONS\n  ( MODEL_TYPE='KMEANS',\n    NUM_CLUSTERS=3,\n    KMEANS_INIT_METHOD='CUSTOM',\n    KMEANS_INIT_COL='init_col') AS\nSELECT\n  init_col,\n  features\nFROM\n  `mydataset.mytable`")]
    [InlineData("CREATE MODEL\n  `mydataset.mymodel`\nOPTIONS\n  ( MODEL_TYPE='PCA',\n    NUM_PRINCIPAL_COMPONENTS=4 ) AS\nSELECT\n  *\nFROM `mydataset.mytable`")]
    [InlineData("CREATE MODEL\n  `mydataset.iris_pca`\nOPTIONS\n  ( MODEL_TYPE='PCA',\n    NUM_PRINCIPAL_COMPONENTS=2,\n    SCALE_FEATURES=FALSE ) AS\nSELECT\n  sepal_length,\n  sepal_width,\n  petal_length,\n  petal_width\nFROM `bigquery-public-data.ml_datasets.iris`")]
    [InlineData("CREATE MODEL `project_id.mydataset.mymodel`\nOPTIONS(MODEL_TYPE='AUTOENCODER',\n        ACTIVATION_FN = 'RELU',\n        BATCH_SIZE = 16,\n        DROPOUT = 0.1,\n        EARLY_STOP = FALSE,\n        HIDDEN_UNITS = [128, 64, 8, 64, 128],\n        LEARN_RATE=0.001,\n        MAX_ITERATIONS = 50,\n        OPTIMIZER = 'ADAGRAD')\nAS SELECT * FROM `project_id.mydataset.mytable`")]
    [InlineData("CREATE MODEL `project_id.mydataset.mymodel`\n OPTIONS(MODEL_TYPE='MATRIX_FACTORIZATION') AS\nSELECT\n  user,\n  item,\n  rating\nFROM\n  `mydataset.mytable`")]
    [InlineData("CREATE MODEL `project_id.mydataset.mymodel`\n OPTIONS(MODEL_TYPE='MATRIX_FACTORIZATION',\n         FEEDBACK_TYPE='IMPLICIT') AS\nSELECT\n  user,\n  item,\n  rating\nFROM\n  `mydataset.mytable`")]
    [InlineData("CREATE MODEL `project_id.mydataset.mymodel`\n OPTIONS(MODEL_TYPE='ARIMA_PLUS',\n         time_series_timestamp_col='date',\n         time_series_data_col='transaction') AS\nSELECT\n  date,\n  transaction\nFROM\n  `mydataset.mytable`")]
    [InlineData("CREATE MODEL `project_id.mydataset.mymodel`\n OPTIONS(MODEL_TYPE='ARIMA_PLUS',\n         time_series_timestamp_col='date',\n         time_series_data_col='transaction',\n         time_series_id_col='company_name') AS\nSELECT\n  date,\n  transaction,\n  company_name\nFROM\n  `mydataset.mytable`")]
    [InlineData("CREATE MODEL `project_id.mydataset.mymodel`\n OPTIONS(MODEL_TYPE='ARIMA_PLUS_XREG',\n         time_series_timestamp_col='date',\n         time_series_data_col='transaction') AS\nSELECT\n  date,\n  transaction,\n  feature1,\n  feature2\nFROM\n  `mydataset.mytable`")]
    [InlineData("CREATE MODEL `project_id.mydataset.mymodel`\n OPTIONS(MODEL_TYPE='ARIMA_PLUS_XREG',\n         time_series_timestamp_col='date',\n         time_series_data_col='transaction',\n         time_series_length_fraction=0.5,\n         min_time_series_length=30) AS\nSELECT\n  date,\n  transaction,\n  feature1,\n  feature2\nFROM\n  `mydataset.mytable`")]
    [InlineData("CREATE MODEL `project_id.mydataset.mymodel`\n OPTIONS(MODEL_TYPE='ONNX',\n         MODEL_PATH=\"gs://bucket/path/to/onnx_model/*\")\n")]
    [InlineData("CREATE MODEL `project_id.mydataset.mymodel`\n OPTIONS(MODEL_TYPE='TENSORFLOW',\n         MODEL_PATH=\"gs://bucket/path/to/saved_model/*\")")]
    [InlineData("CREATE MODEL `project_id.mydataset.mymodel`\n OPTIONS(MODEL_TYPE='TENSORFLOW_LITE',\n         MODEL_PATH=\"gs://bucket/path/to/tflite_model/*\")")]
    [InlineData("CREATE OR REPLACE\n  MODEL\n    `project_id.mydataset.mymodel`\n      INPUT(f1 float64, f2 float64, f3 float64, f4 float64)\n      OUTPUT(predicted_label float64)\n  OPTIONS (\n    MODEL_TYPE = 'XGBOOST',\n    MODEL_PATH = 'gs://bucket-name/xgboost-model/*')")]
    [InlineData("CREATE OR REPLACE\n  MODEL\n    `project_id.mydataset.mymodel`\n  OPTIONS (\n    MODEL_TYPE = 'XGBOOST',\n    MODEL_PATH = 'gs://bucket-name/xgboost-model/*')")]
    [InlineData("CREATE OR REPLACE MODEL `mydataset.tuned_model`\n  REMOTE WITH CONNECTION `myproject.us.test_connection`\n  OPTIONS (\n    endpoint = 'gemini-1.5-pro-002',\n    max_iterations = 500,\n    prompt_col = 'prompt',\n    input_label_cols = ['label'])\nAS\nSELECT\n  CONCAT(\n    'Please do sentiment analysis on the following text and only output a number from 0 to 5 where 0 means sadness, 1 means joy, 2 means love, 3 means anger, 4 means fear, and 5 means surprise. Text: ',\n    sentiment_column) AS prompt,\n  text_column AS label\nFROM `mydataset.emotion_classification_train`")]
    [InlineData("CREATE MODEL `project_id.mydataset.mymodel`\n REMOTE WITH CONNECTION `myproject.us.test_connection`\n OPTIONS(ENDPOINT = 'https://us-central1-aiplatform.googleapis.com/v1/projects/myproject/locations/us-central1/endpoints/1234')")]
    [InlineData("CREATE MODEL `project_id.mydataset.mymodel`\nREMOTE WITH CONNECTION `myproject.us.test_connection`\n OPTIONS(REMOTE_SERVICE_TYPE = 'CLOUD_AI_VISION_V1')")]
    [InlineData("CREATE MODEL `project_id.mydataset.mymodel`\n INPUT(f1 INT64, f2 FLOAT64, f3 STRING, f4 ARRAY)\n OUTPUT(out1 INT64, out2 INT64)\n REMOTE WITH CONNECTION `myproject.us.test_connection`\n OPTIONS(ENDPOINT = 'https://us-central1-aiplatform.googleapis.com/v1/projects/myproject/locations/us-central1/endpoints/1234')")]
    [InlineData("CREATE MODEL `mydataset.transform_model`\n  TRANSFORM(\n    species,\n    island,\n    ML.MAX_ABS_SCALER(culmen_length_mm) OVER () AS culmen_length_mm,\n    ML.MAX_ABS_SCALER(culmen_depth_mm) OVER () AS culmen_depth_mm,\n    ML.MAX_ABS_SCALER(flipper_length_mm) OVER () AS flipper_length_mm,\n    sex,\n    body_mass_g)\n  OPTIONS (\n    model_type = 'transform_only')\nAS (\n  SELECT *\n  FROM `bigquery-public-data.ml_datasets.penguins`\n)")]
    [InlineData("CREATE MODEL `mydataset.mymodel`\nOPTIONS\n  ( MODEL_TYPE = 'LINEAR_REG',\n    MAX_ITERATIONS = 5,\n    INPUT_LABEL_COLS = ['body_mass_g'] ) AS\nSELECT\n  *\nFROM\n  ML.TRANSFORM(\n    MODEL `mydataset.transform_model`,\n    TABLE `bigquery-public-data.ml_datasets.penguins`)\nWHERE body_mass_g IS NOT NULL")]
    [InlineData("CREATE OR REPLACE MODEL `mydataset.mymodel`\n  TRANSFORM(\n    species,\n    island,\n    ML.MAX_ABS_SCALER(culmen_length_mm) OVER () AS culmen_length_mm,\n    ML.MAX_ABS_SCALER(flipper_length_mm) OVER () AS flipper_length_mm,\n    sex,\n    body_mass_g)\n  OPTIONS (\n    model_type = 'linear_reg',\n    input_label_cols = ['body_mass_g'])\nAS (\n  SELECT *\n  FROM `bigquery-public-data.ml_datasets.penguins`\n  WHERE body_mass_g IS NOT NULL\n)")]
    public void Test(string input)
    {
        ParseAllTokens(input, parser => parser.create_model());
    }
}